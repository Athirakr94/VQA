{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModelForImageTextToText, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types = [\"SCN\", \"QLT\", \"INT\", \"LAN\"]\n",
    "# Define a custom dataset\n",
    "\n",
    "\n",
    "class ImageQuestionDataset(Dataset):\n",
    "    def __init__(self, images_path, json_path, processor):\n",
    "        self.images_path = images_path\n",
    "        with open(json_path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_details = self.data[idx]\n",
    "        frame_id = frame_details[\"frame_id\"]\n",
    "        conversations = frame_details[\"conversations\"]\n",
    "        sample = []\n",
    "\n",
    "        # Process each question in the frame\n",
    "        for converse in conversations:\n",
    "            question = converse[\"question\"]\n",
    "            options = converse[\"options\"]\n",
    "            answer = converse[\"answer\"]\n",
    "            question_type = converse[\"question_type\"]\n",
    "\n",
    "            if question_type not in question_types:\n",
    "                continue\n",
    "\n",
    "            # Load all images for the frame\n",
    "            image_folder = os.path.join(self.images_path, frame_id)\n",
    "            images_list = []\n",
    "            for image_file in os.listdir(image_folder):\n",
    "                img = Image.open(os.path.join(\n",
    "                    image_folder, image_file)).convert(\"RGB\")\n",
    "                images_list.append(img)\n",
    "\n",
    "            # Create input data for the model\n",
    "            prompt = f\"<image> \" * len(images_list) + \\\n",
    "                \"<bos> \" + f\"{question} \\n {options}\"\n",
    "            prompt += \" Choose the Correct Option.\"\n",
    "\n",
    "            sample.append({\n",
    "                \"images\": images_list,\n",
    "                \"prompt\": prompt,\n",
    "                \"answer\": answer,\n",
    "                \"question_type\": question_type\n",
    "            })\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2f4071130849c39ef9a285dcc2ded9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate model and processor\n",
    "# \"google/paligemma-3b-mix-224\" should be changed to other model id\n",
    "model_id = \"google/paligemma-3b-mix-224\"\n",
    "device = \"cuda:5\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id, device_map=device).eval()\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_images_path = \"/raid/ai23mtech14006/Test_WC/maplm_v1_5/data/val/images/\"\n",
    "train_json_path = \"/raid/ai23mtech14006/Test_WC/maplm_v1_5/data/val/val.json\"\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = ImageQuestionDataset(train_images_path, train_json_path, processor)\n",
    "dataloader = DataLoader(dataset, batch_size=16,\n",
    "                        shuffle=False, collate_fn=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 94/94 [1:12:30<00:00, 46.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /raid/ai23mtech14006/Test_WC/palli_224_Output_20241214_130311.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def predict_batch(batch, model, processor):\n",
    "    predictions = []\n",
    "\n",
    "    for b in batch:\n",
    "        for sample in b:\n",
    "            images = sample[\"images\"]\n",
    "            prompt = sample[\"prompt\"]\n",
    "            correct_answer = sample[\"answer\"]\n",
    "\n",
    "            # Prepare inputs\n",
    "            inputs = processor(images=images, text=prompt, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "            # Generate predictions\n",
    "            output = model.generate(**inputs, max_new_tokens=20)\n",
    "            decoded = processor.decode(\n",
    "                output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "            # Extract the predicted option\n",
    "            question = prompt.split(\"<bos>\")[1][1:]\n",
    "\n",
    "            if decoded.startswith(question):\n",
    "                decoded = decoded[len(question):].strip()\n",
    "\n",
    "            # Append results for saving to XLSX\n",
    "            predictions.append({\n",
    "                \"Question\": question,\n",
    "                \"Prediction\": decoded,\n",
    "                \"Answer\": correct_answer\n",
    "            })\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Create an XLSX file\n",
    "output_filename = f\"palli_224_Output_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "output_path = os.path.join(os.getcwd(), output_filename)\n",
    "all_predictions = []\n",
    "\n",
    "count = 0\n",
    "# Iterate through DataLoader with tqdm for progress monitoring\n",
    "for batch in tqdm(dataloader, desc=\"Processing Batches\"):\n",
    "    batch_predictions = predict_batch(batch, model, processor)\n",
    "    all_predictions.extend(batch_predictions)\n",
    "\n",
    "# Save all predictions to an Excel file\n",
    "df = pd.DataFrame(all_predictions)\n",
    "df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Specifications\n",
    "\n",
    "Model 1 : google/paligemma-3b-mix-224 \\\n",
    "Parameters : 3 Billion \\\n",
    "Time Taken to Infer : 72 Minutes \\\n",
    "GPU : Tesla V100 32GB \\\n",
    "Weights : Pre-trained (Zero-Shot)\n",
    "\n",
    "Model 2 : google/paligemma-3b-mix-448 \\\n",
    "Parameters : 3 Billion \\\n",
    "Time Taken to Infer : 240 Minutes \\\n",
    "GPU : Tesla V100 32GB \\\n",
    "Weights : Pre-trained (Zero-Shot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parser Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : paligemma-3b-mix-224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 6000/6000 [00:53<00:00, 112.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 12.40%\n",
      "Precision: 28.27%\n",
      "Recall: 12.40%\n",
      "F1 Score: 16.15%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "file_path = '/raid/ai23mtech14006/Test_WC/palli_224_Output_20241214_130311.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Check if necessary columns exist\n",
    "required_columns = ['Question', 'Prediction', 'Answer']\n",
    "if not all(column in df.columns for column in required_columns):\n",
    "    raise ValueError(\n",
    "        f\"DataFrame must contain the following columns: {required_columns}\")\n",
    "\n",
    "# Load a pre-trained Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Initialize lists for true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Process each row in the DataFrame\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"):\n",
    "    question = row['Question']\n",
    "    prediction = row['Prediction'].strip().lower()\n",
    "\n",
    "    try:\n",
    "        correct_option_index = int(row['Answer'])\n",
    "    except ValueError:\n",
    "        print(f\"Invalid answer index at row {index}\")\n",
    "        continue\n",
    "\n",
    "    # Extract the options from the question\n",
    "    options_start = question.find('[')\n",
    "    options_end = question.find(']')\n",
    "\n",
    "    if options_start != -1 and options_end != -1:\n",
    "        options = question[options_start + 1:options_end]\n",
    "        options_list = [opt.strip().strip(\"'\").lower()\n",
    "                        for opt in options.split(',')]\n",
    "\n",
    "        # Ensure the correct_option_index is within the range of options_list\n",
    "        if 0 <= correct_option_index < len(options_list):\n",
    "            # Get the correct answer text using the index\n",
    "            correct_answer = options_list[correct_option_index]\n",
    "\n",
    "            # Compute semantic similarity\n",
    "            embeddings = model.encode(\n",
    "                [prediction, correct_answer], convert_to_tensor=True)\n",
    "            similarity_score = util.cos_sim(\n",
    "                embeddings[0], embeddings[1]).item()\n",
    "\n",
    "            # Add to lists for metrics calculation\n",
    "            y_true.append(correct_answer)\n",
    "            y_pred.append(prediction if similarity_score >\n",
    "                          0.98 else 'incorrect')\n",
    "        else:\n",
    "            print(f\"Invalid answer index at row {index}\")\n",
    "    else:\n",
    "        print(f\"Options not found in question at row {index}\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(\n",
    "    y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Display metrics\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1 Score: {f1:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WACV_25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
